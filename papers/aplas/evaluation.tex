\section{Evaluation}
In our study we compared the CPD adaptation for \mk{} and the new non-conjunctive partial deduction.
For some programs we have also employed the branching heuristic instead of the deterministic unfolding in the CPD to check whether it can improve the quality of the specialization.
We measured the execution time of each specialized program for some queries and compared it with the execution time of the original program.

We used the following programs to test the specializers on.
\begin{itemize}
  \item A program to compute a concatenation of three lists.
  \item A program to compute both the length of the list and its maximal element.
  \item Two implementations of an evaluator of logic formulas.
  \item Two implementations of a typechecker for a small expression language.
  \item A program to compute a unifier of two terms.
  \item A program to search for paths of a specific length in a graph.
\end{itemize}

The last two relations are described in~\cite{lozov2019relational} thus we will only briefly describe them in this paper.

We focused on these particular examples because they are examples of relational interpreters which are natural and observable.

\subsection{Concatenation of Three Lists}

The relation \lstinline{doubleAppend$^o$} concatenates three lists by a conjunction of two calls of the \lstinline{append$^o$} relation (see fig.~\ref{doubleApp}).
These two calls share a variable --- an intermediate list \lstinline{ts} --- which should be treated with care during specialization.
Partial deduction does ignore the sharing of the variables which renders the approach to be unproductive for this kind of relations.
This is why this relation is particularly well known in the conjunctive partial deduction work.

The first list gets traversed twice to construct the result.
First, when the intermidiate list \lstinline{ts} is constructed during the first \lstinline{append$^o$} call and then, when \lstinline{ts} is read during the second call.
This double traversal negatively impacts the execution time.

\begin{figure*}[!h]
  \centering
  \begin{minipage}{0.6\textwidth}
    \begin{lstlisting}[label={doubleApp}, caption={Concatenation of three lists}, captionpos=b, frame=tb]
  let doubleAppend$^o$ xs ys zs res =
    fresh (ts) (
      append$^o$ xs ys ts /\ append$^o$ ts zs res)

  let rec append$^o$ xs ys zs = conde [
    (xs === [] /\ ys === zs);
    fresh (h t r) (
      xs === (h % t) /\
      zs === (h % r) /\
      append$^o$ t ys r)]
    \end{lstlisting}
  \end{minipage}
\end{figure*}

The better implementation of this relation (see fig.~\ref{doubleApp:etalon}) does not traverse the first list twice.
This etalon implementation is generated with the conjunctive partial deduction.

\begin{figure*}[!h]
  \centering
  \begin{minipage}{0.6\textwidth}
    \begin{lstlisting}[label={doubleApp:etalon}, caption={Etalon implementation of concatenation of three lists}, captionpos=b, frame=tb]
  let doubleAppend$^o$ xs ys zs res = conde [
    (xs === [] /\ append$^o$ ys zs res);
    fresh (h t r) (
      xs === h % t /\
      res === h % r /\
      doubleAppend$^o$ t ys zs r)]
    \end{lstlisting}
  \end{minipage}
\end{figure*}

We run all translated programs in the forward and the backward direction.
The forward direction \lstinline{doubleAppend$^o$ x y z ?} concatenates three given lists: the first one of length 700, the second and the third --- of length 1.
When run in the backward direction \lstinline{doubleAppend$^o$ ? ? ? r} , it searches for the first 100 list triples whose concatenation gives the given list of length 700.

There is no significant difference in the execution time in the backward direction between different specialized versions~\ref{tbl:doubleApp}.
However the execution time in the backward direction differs: the program generated by Ecce shows the same speedup as the etalon program, while non-conjunctive partial deduction slows the program down.
\todo{WHY?}

\begin{table}
  \centering
  \begin{tabular}{c||c||c}
                   & forward & backward \\
  \hline\hline
  Original         & 0.0040s & 0.0195s \\ \hline
  Ecce             & 0.0031s & 0.0201s \\ \hline
  Non-CPD          & 0.0055s & 0.0202s \\ \hline
  Etalon           & 0.0031s & 0.0203s \\
  \end{tabular}
  \caption{Evaluation results for doubleAppendo}
  \label{tbl:doubleApp}
\end{table}

\subsection{Maximum Element and Length of a List}

The relation \lstinline{maxLenght$^o$} computes both the length of the list and its maximum element (see fig.~\ref{cpd:maxandlength}) by concatenation of two relation calls.
This relation traverses the list \lstinline{xs} twice: first to compute the maximum and then to compute the length of the list.
It can be transformed in such a way that the list is only traversed once while computing both components of the result simultaneously.
This transformation is called \emph{tupling} and can be achieved with conjunctive partial deduction.

\begin{figure*}[!h]
  \centering
  \begin{minipage}{0.85\textwidth}
\begin{lstlisting}[label={cpd:maxandlength}, caption={Maximum element and length of the list}, captionpos=b, frame=tb]
  let maxLength$^o$ xs m l = max$^o$ xs m /\ length$^o$ xs l
  let rec length$^o$ xs l = conde [
    (xs === [] /\ l === zero);
    (fresh (h t m) (
      xs === h % t /\ l === succ m /\ length$^o$ t m))]
  let max$^o$ xs m = max$_1^o$ xs zero m
  let rec max$_1^o$ xs n m = conde [
    (xs === [] /\ m === n);
    (fresh (h t) (
      (xs === h % t) /\
      (conde [
        (le$^o$ h n ^true /\ max$_1^o$ t n m);
        (gt$^o$ h n ^true /\ max$_1^o$ t h m)])))]
  let rec le$^o$ x y b = conde [
    (x === zero /\ b === ^true);
    (fresh (x$_1$) (x === succ x$_1$ /\ y === zero /\ b === ^false));
    (fresh (x$_1$ y$_1$) (x === succ x$_1$ /\ y === succ y$_1$ /\ le$^o$ x$_1$ y$_1$ b))]
  let rec gt$^o$ x y b = conde [
    (x === zero /\ b === ^false);
    (fresh (x$_1$) (x === succ x$_1$ /\ y === zero /\ b === ^false));
    (fresh (x$_1$ y$_1$) (x === succ x$_1$ /\ y === succ y$_1$ /\ gt$^o$ x$_1$ y$_1$ b))]
  \end{lstlisting}
\end{minipage}
\end{figure*}

The etalon implementation is shown in fig.~\ref{etalon:maxandlength}.
It uses a recursive relation to compute the length and maximum element simultaneously while traversing the list once.

\begin{figure*}[!h]
  \centering
  \begin{minipage}{0.7\textwidth}
\begin{lstlisting}[label={etalon:maxandlength}, caption={Etalon implementation of maxlengtho}, captionpos=b, frame=tb]
  let maxLength$^o$ xs m l = maxLength$_1^o$ xs m zero l
  let rec maxLength$_1^o$ xs m n l = conde [
    (xs === [] /\ m === n /\ l === zero);
    (fresh (h t l$_1$)
       (xs === h % t) /\
       (l === succ l$_1$) /\
       (conde [
         (le$^o$ h n ^true /\ maxLength$_1^o$ t m n l);
         (gt$^o$ h n ^true /\ maxLength$_1^o$ t m h l)]))]
  \end{lstlisting}
\end{minipage}
\end{figure*}

We measured the execution time of \lstinline{maxLength$^o$ lst m l}, where \lstinline{lst} is a list of Peano numbers from $1$ to $100$.
Note, that the second disjunct in the implementation of both \lstinline{le$^o$} and \lstinline{gt$^o$} can never contribute into the result of \lstinline{maxLength$^o$} execution.
Thus among others we compared two etalon implentations: one includes these disjuncts, while the other removes them (see table~\ref{tbl:maxlen})


\begin{table}
  \centering
  \begin{tabular}{c||c}
                   & [1..100] \\ \hline\hline
  Original         & 2.286ms  \\ \hline
  Etalon           & 4.623ms  \\ \hline
  Etalon removed   & 3.133ms  \\ \hline
  Ecce             & 1.701ms  \\ \hline
  Non-CPD          & 2.578ms
  \end{tabular}

  \caption{Execution time of maxlengtho}
  \label{tbl:maxlen}
\end{table}

Surprising enough, the execution time of the etalon program is worse than of the original.
Ecce succeeds at improving the program performance, while non-conjunctive partial deduction worsens it a little.
\todo{why}

\subsection{Evaluator of Logic Formulas}

The relation \lstinline{eval$^o$} describes an evaluation of a subset of first-order logic formulas in a given substitution.
It has 3 arguments.
The first argument is a list of boolean values which serves as a substitution.
The $i$-th value of the substitution is the value of the $i$-th variable.
The second argument is a formula with the following abstract syntax.
A formula is either a \emph{variable} represented with a Peano number, a \emph{negation} of a formula, a \emph{conjunction} of two formulas or a \emph{disjunction} of two formulas.
The third argument is the value of the formula in the given substitution.

All examples of \mk{} relations in this paper are written in \oc{}\footnote{\oc{}: statically typed \mk{} embedding in \ocaml{}. The repository of the project: \url{https://github.com/JetBrains-Research/OCanren}} syntax.
We specialize the \lstinline{eval$^o$} relation to synthesize formulas which evaluate to \lstinline{^true}\footnote{An arrow lifts ordinary values to the logic domain}.
To do so, we run the specializer for the goal with the last argument fixed to \lstinline{^true}, while the first two arguments remain free variables.
Depending on the way the \lstinline{eval$^o$} is implemented, different specializers generate significantly different residual programs.

\subsubsection{The Order of Relation Calls}

One possible implementation of the evaluator in the syntax of \oc{} is presented in listing~\ref{eval:last}.
Here the relation \lstinline{elem$^o$ subst v res} unifies \lstinline{res} with the value of the variable \lstinline{v} in the list \lstinline{subst}.
The relations \lstinline{and$^o$}, \lstinline{or$^o$}, and \lstinline{not$^o$} encode corresponding boolean operations.

\begin{figure*}[!h]
  \centering
  \begin{minipage}{0.95\textwidth}
    \begin{lstlisting}[label={eval:last}, caption={Evaluator of formulas with boolean operation last}, captionpos=b, frame=tb]
  let rec eval$^o$ subst fm res = conde [
    fresh (x y z v w) (
      (fm === var v /\ elem$^o$ subst v res);
      (fm === conj x y /\ eval$^o$ st x v /\ eval$^o$ st y w /\ and$^o$ v w res);
      (fm === disj x y /\ eval$^o$ st x v /\ eval$^o$ st y w /\ or$^o$ v w res);
      (fm === neg x /\ eval$^o$ st x v /\ not$^o$ v res))]
    \end{lstlisting}
  \end{minipage}
\end{figure*}

Note, that the calls to boolean relations \lstinline{and$^o$}, \lstinline{or$^o$}, and \lstinline{not$^o$} are placed last within each conjunction.
This poses a challenge to the CPD-based specializers.
Conjunctive partial deduction unfolds relation calls from left to right, so when specializing this relation for running backwards (i.e. considering the goal \lstinline{eval$^o$ subst fm ^true}), it fails to propagate the direction data onto recursive calls of \lstinline{eval$^o$}.
Knowing that \lstinline{res} is \lstinline{^true}, we can conclude that in the call \lstinline{and$^o$ v w res} variables \lstinline{v} and \lstinline{w} have to be \lstinline{^true} as well.
There are three possible options for these variables in the call \lstinline{or$^o$ v w res} and one for the call \lstinline{not$^o$}.
These variables are used in recursive calls of \lstinline{eval$^o$} and thus restrict the result of driving them.
CPD fails to recognize this, and thus unfolds recursive calls of \lstinline{eval$^o$} applied to fresh variables.
It leads to over-unfolding, big residual programs and less than optimal performance.

The non-conjunctive partial deduction first unfolds those calls which are selected with the heuristic.
Since exploring boolean operations makes more sense, they are unfolded before recursive calls of \lstinline{eval$^o$}.
The way non-conjunctive partial deduction treats this program is the same as it treats the other implementation in which boolean operations are moved to the left, as shown in listing~\ref{eval:fst}.
This program is easier for CPD to transform which demonstrates how unequal is the behaviour of CPD for similar programs.

\begin{figure*}[!h]
  \centering
  \begin{minipage}{0.95\textwidth}
    \begin{lstlisting}[label={eval:fst}, caption={Evaluator of formulas with boolean operation second}, captionpos=b, frame=tb]
  let rec eval$^o$ subst fm res = conde [
    fresh (x y z v w) (
      (fm === var v /\ elem$^o$ subst v res);
      (fm === conj x y /\ and$^o$ v w res /\ eval$^o$ st x v /\ eval$^o$ st y w);
      (fm === disj x y /\ or$^o$ v w res /\ eval$^o$ st x v /\ eval$^o$ st y w);
      (fm === neg x /\ not$^o$ v res /\ eval$^o$ st x v))]
    \end{lstlisting}
  \end{minipage}
\end{figure*}

\subsubsection{Unfolding of Complex Relations}

Depending on the way a relation is implemented, it may take a different number of driving steps to reach the point when any useful information is derived through its unfolding.
Partial deduction tries to unfold every relation call unless it is unsafe, but not all relation calls serve to restrict the search space and thus should be unfolded.
In the implementation of \lstinline{eval$^o$} boolean operations can effectively restrict variables within the conjunctions and should be unfolded until they do.
But depending on the way they are implemented, the different number of driving steps should be performed for that.
The simplest way to implement these relations is with a table as demonstrated with the implementation of \lstinline{not$^o$} in listing~\ref{not:table}.
It is enough to unfold such relation calls once to derive useful information about variables.

\begin{figure*}[!h]
  \centering
  \begin{minipage}{0.45\textwidth}
    \begin{lstlisting}[label={not:table}, caption={Implementation of boolean \lstinline{not} as a table}, captionpos=b, frame=tb]
  let not$^o$ x y = conde [
     (x === ^true /\ y === ^false;
      x === ^false /\ y === ^true)]
    \end{lstlisting}
  \end{minipage}
\end{figure*}

The other way to implement boolean operations is via one basic boolean relation such as \lstinline{nand$^o$} which is, in turn, has a table-based implementation (see listing~\ref{not:nando}).
It will take several sequential unfoldings to derive that variables \lstinline{v} and \lstinline{w} should be \lstinline{^true} when considering a call \lstinline{and$^o$ v w ^true} implemented via a basic relation.
Non-conjunctive partial deduction drives the selected call until it derives useful substitutions for the variables involved while CPD with deterministic unfolding may fail to do so.

\begin{figure*}[!h]
  \centering
  \begin{minipage}{0.85\textwidth}
    \begin{lstlisting}[label={not:nando}, caption={Implementation of boolean operation via \lstinline{nand}}, captionpos=b, frame=tb]
  let not$^o$ x y = nand$^o$ x x y

  let or$^o$ x y z = nand$^o$ x x xx /\ nand$^o$ y y yy /\ nand$^o$ xx yy z

  let and$^o$ x y z = nand$^o$ x y xy /\ nand$^o$ xy xy z

  let nand$^o$ a b c = conde [
    ( a === ^false /\ b === ^false /\ c === ^true );
    ( a === ^false /\ b === ^true /\ c === ^true );
    ( a === ^true /\ b === ^false /\ c === ^true );
    ( a === ^true /\ b === ^true /\ c === ^false )]
    \end{lstlisting}
  \end{minipage}
\end{figure*}

\subsubsection{Evaluation Results}
In our study, we considered two implementations of \lstinline{eval$^o$}, one we call \lstinline{plain} and the other --- \lstinline{last}, and compared how specializers behave on them.
The \lstinline{plain} relation uses table-based boolean operations and places them further to the left in each conjunction.
The relation \lstinline{last} employs boolean operations implemented via \lstinline{nand$^o$} and place them at the end of each conjunction.
These two programs are complete opposites from the standpoint of CPD.
We measured the time necessary to generate $1000$ formulas over two variables which evaluate to \lstinline{^true} (averaged over 10 runs).


\begin{table}
  \centering
  \begin{tabular}{c||c||c}
                   & last    & plain  \\
  \hline\hline
  Original         & 0.695s  & 1.426s \\
  \hline
  CPD              & 1.721s  & 0.168s \\
  \hline
  Ecce             & 0.205s  & 0.264s \\
  \hline
  Non-CPD          & 0.132s  & 0.137s \\
  \hline
  Branching        & 0.468s  & 0.179s \\
  \end{tabular}

  \caption{Evaluation results}
  \label{tbl:eval}
\end{table}


\subsection{Unification and Path Search}

Besides evaluator of logic formulas we also run the transformers on the relation \lstinline{unify} which searches for a unifier of two terms and a relation \lstinline{isPath} specialized to search for paths in the graph.
These two relations are described in paper~\cite{lozov2019relational} so we will not go into too many details here.

The \lstinline{unify} relation was executed to find a unifier of two terms $f(X, X, g(Z, t))$ and $f(g(p, L), Y, Y)$.
The original \mk{} program fails to terminate on this goal in 30 seconds.
On this example, the most performant is the program generated by CPD (0.352 seconds) while the program generated by adding branching heuristic also fails to terminate in 30 seconds.
The non-conjunctive partial deduction shows some improvement with the residual program terminated within 1.947 seconds.
While driving this program, the non-conjunctive partial deduction does too much unfolding which negatively impacts the running time as compared to CPD.

The last test executed \lstinline{isPath} relation to search for 3 paths of length 7 in the graph with 20 vertices and 30 edges.
On this program, non-conjunctive partial deduction showed better transformation results than CPD, although the difference is not that drastic.

All evaluation results are presented in the table~\ref{tbl:unify}.
Each column corresponds to the relation being run as described above.
The row marked ``Original'' contains the running time of the original \mk{} relation before specialization, ``CPD'' and ``Non-CPD'' correspond to conjunctive and non-conjunctive partial deduction respectively while ``Branching'' is for the CPD modified with the branching heuristic.

\begin{table}
  \centering
  \begin{tabular}{c||c|c|c||c}
                   & \multicolumn{3}{c||}{unify} & isPath \\
  \hline
                   & first  & second & third     &        \\
  \hline\hline
  Original         & $0.247*10^{-4}s$ & $>30s$ (oum?) & $>30s$ (oum?) & $23.743s$ \\
  \hline
  CPD              & $0.081*10^{-4}s$ & $0.017s$ & $0.343s$  & $2.999s$  \\
  \hline
  Non-CPD          & $0.084*10^{-4}s$ & $0.021s$ & $2.198s$  & $1.786s$  \\
  \hline
  Ecce             & $0.128*10^{-4}s$ & $0.026s$ & $1.340s$  & $1.292s$ \\
  \hline
  Branching        & $0.205*10^{-4}s$ & $0.101s$ & $>30s$ (oum?) & N/A \\
  \hline
  \end{tabular}

  \caption{Evaluation results of unification and path search}
  \label{tbl:unify}
\end{table}

\subsection{Typechecker-Term Generator}

This relation implements a typechecker for a tiny language.
Being executed in the backward direction it serves as a generator of terms of the given type.
The abstract syntax of the language is presented below.
The variables are represented with de Bruijn indices, thus let-binding does not specify which variable is being bound.


% \begin{align*}
%   &type \ term = \\
%   &| \ BConst \ of \ Bool \\
%   &| \ IConst \ of \ Int \\
%   &| \ Var \ of \ Int \\
%   &| \ Plus \ of \ term * term \\
%   &| \ Mult \ of \ term * term \\
%   &| \ Eq \ of \ term * term \\
%   &| \ Lt \ of \ term * term \\
%   &| \ Let \ of \ term * term \\
%   &| \ If \ of \ term * term * term
% \end{align*}

\begin{align*}
  &type \ term = \\
  &| \ BConst \ of \ Bool \\
  &| \ IConst \ of \ Int \\
  &| \ Var \ of \ Int \\
  &| \ term + term \\
  &| \ term * term \\
  &| \ term = term \\
  &| \ term < term \\
  &| \ \underline{let} \ term \ \underline{in} \ term \\
  &| \ \underline{if} \ term \ \underline{then} \ term \ \underline{else} \ term
\end{align*}


The typing rules are straightforward and are presented below.
Boolean and integer constants have the corresponding types regardless of the environment.
Only terms of type integer can be summed up, multiplied or checked for being less or equal.
Any terms of the same type can be checked for equality.
If-then-else expression typechecks only if its condition is of type boolean, while both then- and else-branches have the same type.
An environment $\Gamma$ is an ordered list, in which the $i$-th element is the type of the variable with the $i$-th de Bruijn index.
To typecheck a let-binding, first, the term being bound is typechecked and is added in the beginning of the environment $\Gamma$, and then the body is typechecked in the context of the new environment.
Typechecking a variable with the index $i$ boils down to getting a $i$-th element of the list.

\begin{table}
  \setlength{\tabcolsep}{0.5cm}
  \centering
  \begin{tabular}{c c}
    \infer[]{\Gamma \vdash IConst \ i : Int}{} &
    \infer[]{\Gamma \vdash BConst \ b : Bool}{} \vspace{0.5cm} \\

    \infer[]{\Gamma \vdash t + s : Int}{\Gamma \vdash t : Int, \Gamma \vdash  s : Int} &
    \infer[]{\Gamma \vdash t * s : Int}{\Gamma \vdash t : Int, \Gamma \vdash  s : Int} \vspace{0.5cm} \\

    \infer[]{\Gamma \vdash t = s : Bool}{\Gamma \vdash t : \tau, \Gamma \vdash  s : \tau} &
    \infer[]{\Gamma \vdash t < s : Bool}{\Gamma \vdash t : Int, \Gamma \vdash  s : Int} \vspace{0.5cm} \\

    \infer[]{\Gamma \vdash \underline{let} \ v \ b : \tau}{\Gamma \vdash v : \tau_v, \ (\tau_v :: \Gamma) \vdash b : \tau} &
    \infer[\Gamma \lbrack v \rbrack = \tau]{\Gamma \vdash Var \ v : \tau}{} \vspace{0.5cm} \\

    \multicolumn{2}{c}{
      \infer[]{\Gamma \vdash \underline{if} \ c \ \underline{then} \ t \ \underline{else} \ s : \tau}{\Gamma \vdash c : Bool, \Gamma \vdash t : \tau, \Gamma \vdash s : \tau}
    }


  \end{tabular}
\end{table}

We compared two possible implementations of these typing rules.
The first one is obtained by unnesting of the functional program as described in~\cite{lozov2019relational}.
The second program is hand-written in \oc{}.
Each implementation has been transformed with non-conjunctive partial deducer and by Ecce.

We measured the time needed to generate 100 terms of type integer (averaged over 10 iterations).
Ecce significantly worsens the execution time for both implementations.
Non-conjunctive partial deduction improves the first implementation a little bit, while worsening the performance of the second implementation 3 times.

\begin{table}
  \centering
  \begin{tabular}{c||c||c}
              & Implementation 1 & Implementation 2 \\ \hline\hline
  Original    & 0.464s           & 0.057s           \\ \hline
  Non-CPD     & 0.448s           & 0.154s           \\ \hline
  Ecce        & 1.518s           & 2.543s           \\
  \end{tabular}

  \caption{Running time of generating 100 closed terms of type Int}
  \label{tbl:eval}
\end{table}

\todo{why}