\section{Evaluation}
In our study we compared the new conservative partial deduction with the \ecce partial deduction system.
\ecce is designed for \pro programming language and cannot be directly applied to \mk.
To be able to compare our approach with \ecce, we converted each input program first to the pure subset of \pro, then transformed it with \ecce, and then we converted the result back to \mk.
The coversion to \pro is a simple syntactic conversion.
In conversion from \pro to \mk, a conjunction is generated by each horn clause in which unifications are placed before any relation call.
This mimics in \mk the execution order of \pro program within a conjunction.

The set of benchmarks consist of both examples from the literature on partial deduction and programs of our own creation.
The first two programs are well-known in conjunctive partial deduction literature~\cite{de1999conjunctive}.
The second two are introduced in the paper on relational interpreters~\cite{lozov2019relational}.
The last two are examples of relational interpreters created by us which are observable, but non-trivial.
In the last two examples we explore how different implementations of the same relation affects the quality of transformations.

The \lstinline{doubleAppend$^o$} program concatenates three lists of numbers by computing a conjunction of two calls of a relation which concatenates two lists.
This example is prominent in CPD literature, since it demonstrates \emph{deforestation} --- a transformation which gets rid of intermidiate datastructures.
This transformation cannot be done with the earlier partial deduction approach, since the relation uses a variable shared between two relation calls within a conjunction which requires the transformation to treat conjunctions as a whole.
We explore how the fact that our approach sometimes splits conjunctions ignoring the variable sharing affects the quality of transformation.

The \lstinline{maxLength$^o$} program computes the maximum element of the list as well as its length.
In this program an input list is shared between the call of the relation to compute the maximum element and the relation to compute the length of the list.
This sharing leads to the list being traversed twice during execution.
This example is used to demonstrate \emph{tupling}: the transformation in which multiple traversals of the same data structure are replaced with a single traversal which computes all the necessary results simultaneously.
CPD performes tupling more often than our approach, and we explore how it affects the performance of the transformed program.

The \lstinline{isPath} and \lstinline{unify} relations demonstrate the relation interpretation approach in which a relation is generated from a functional program.
Partial deduction is capable to improve the execution time of the generated relations in the given direction.
These two relations are described in~\cite{lozov2019relational} thus we will only briefly describe them in this paper.
Here the aim is to study if our approach can help to achieve comparable performance improvement as \ecce.

The \lstinline{eval$^o$} relation implements an evaluator of a subset of propositional formulas.
We consider four different implementations of this relation to explore how the way program is implemented can affect the quality of transformation.
Depending on the implementation, \ecce generates programs of varying performance, while the execution time of the program generated by our approach is similar.

The \lstinline{typecheck$^o$} relation implements a typechecker for a tiny expression language.
We consider two different implementations of this relation: one written by hand and the other generated from the functional program.
We demonstrate how much these implementations differ in terms of performance before and after transformations.

In this study we only measured the execution time for the sample queries, averaging them over multiple runs.
All examples of \mk relations in this paper are written in \oc\footnote{\oc: statically typed \mk embedding in \ocaml. The repository of the project: \url{https://github.com/JetBrains-Research/OCanren}}.
The queries were run on a laptop running Ubuntu 18.04 with quad core Intel Core i5 2.30GHz CPU and 8 GB of RAM.

The tables and graphs use the following denotations.
\emph{Original} represents the execution time of a program before any transformations were applied; \emph{ECCE} --- of the program transformed with \ecce with default conjunctive control setting; \emph{ConsCPD} --- of the program transformed by our approach.
The first two examples also contain \emph{Ideal} row which contain the execution time of the ideal implementations of the relations presented in the paper~\cite{de1999conjunctive}.

\subsection{Concatenation of Three Lists}

The relation \lstinline{doubleAppend$^o$} concatenates three lists by a conjunction of two calls of the \lstinline{append$^o$} relation (see fig.~\ref{doubleApp}).
These two calls share a variable --- an intermediate list \lstinline{ts}.
The list \lstinline{xs} is traversed twice to construct the result: first when \lstinline{ts} is constructed and then, when \lstinline{ts} is traversed during the second call.
This double traversal negatively impacts the execution time, but it can be removed by deforestation.

\begin{figure*}[!h]
  \centering
  \begin{minipage}{0.6\textwidth}
    \begin{lstlisting}[label={doubleApp}, caption={Concatenation of three lists}, captionpos=b, frame=tb]
  let doubleAppend$^o$ xs ys zs res =
    fresh (ts) (
      append$^o$ xs ys ts /\ append$^o$ ts zs res)

  let rec append$^o$ xs ys zs = conde [
    (xs === [] /\ ys === zs);
    fresh (h t r) (
      xs === (h % t) /\
      zs === (h % r) /\
      append$^o$ t ys r)]
    \end{lstlisting}
  \end{minipage}
\end{figure*}

The better implementation of this relation (see fig.~\ref{doubleApp:ideal}) does not traverse the first list twice.
It first recursively copies \lstinline{xs} into the beginning of \lstinline{res}, and only when \lstinline{xs} is fully consumed, it calls the \lstinline{append$^o$} to concatenate \lstinline{ys} and \lstinline{zs}.
This implementation is provided as the ideal implementation of \lstinline{doubleAppend$^o$} in~\cite{de1999conjunctive}.

\begin{figure*}[!h]
  \centering
  \begin{minipage}{0.6\textwidth}
    \begin{lstlisting}[label={doubleApp:ideal}, caption={Ideal implementation of concatenation of three lists}, captionpos=b, frame=tb]
  let doubleAppend$^o$ xs ys zs res = conde [
    (xs === [] /\ append$^o$ ys zs res);
    fresh (h t r) (
      xs === h % t /\
      res === h % r /\
      doubleAppend$^o$ t ys zs r)]
    \end{lstlisting}
  \end{minipage}
\end{figure*}

To automatically transform the initial program into the ideal implementation, the transformer should treat the conjuncts which share variables with care.
Partial deduction splits any conjunction into its subconjunctions, regardless variable sharing, while CPD only splits conjunctions when potential non-termination is detected.
Conservative partial deduction processes subconjunctions in isolation and then joins them back together, if it can help to restrict the search space.
In this example, ConsPD fails to perform deforestation: ConsPD first splits the conjunction \lstinline{append$^o$ xs ys ts /\ append$^o$ ts zs rs} into two relation calls of \lstinline{append$^o$}, then unfolds the first call, but since the second call is a renaming of the first one, it is not unfolded.
The generated program is almost the same as the original: the only difference being that the fresh variables are introduced on the toplevel.


We run all programs in the forward and the backward direction.
The forward direction \lstinline{doubleAppend$^o$ x y z ?} concatenates three given lists: the first one of length 700, the second and the third --- of length 1.
The backward direction \lstinline{doubleAppend$^o$ ? ? ? r} searches for the first 100 list triples whose concatenation gives the given list of length 700.

\begin{table}
  \centering
  \begin{tabular}{c||c||c}
                  & forward & backward \\
  \hline\hline
  Original        & 34.8ms & 1.6ms \\ \hline
  \ecce           & 26.7ms & 1.7ms \\ \hline
  Ideal           & 26.9ms & 1.7ms \\ \hline
  ConsCPD         & 47.6ms & 1.7ms
  \end{tabular}
  \caption{Evaluation results for doubleAppendo}
  \label{tbl:doubleApp}
\end{table}

\includegraphics{graphs/doubleApp.pdf}

There is no significant difference in the execution time in the backward direction between different specialized versions (see table~\ref{tbl:doubleApp}).
However the execution time in the backward direction differs: the program generated by \ecce shows the same speedup as the ideal program, while conservative partial deduction slows the program down.
The reason behind the slowdown is the premature introduction of fresh variables which is significant for the input data of this size.

\subsection{Maximum Element and Length of a List}

The relation \lstinline{maxLenght$^o$} computes both the length of the list and its maximum element (see fig.~\ref{cpd:maxandlength}) by concatenation of two relation calls.
This relation traverses the list \lstinline{xs} twice: first to compute the maximum and then to compute the length of the list.
It can be transformed in such a way that the list is only traversed once while computing both components of the result simultaneously.
This transformation is called \emph{tupling} and can be achieved with conjunctive partial deduction.

\begin{figure*}[!h]
  \centering
  \begin{minipage}{0.85\textwidth}
\begin{lstlisting}[label={cpd:maxandlength}, caption={Maximum element and length of the list}, captionpos=b, frame=tb]
  let maxLength$^o$ xs m l = max$^o$ xs m /\ length$^o$ xs l
  let rec length$^o$ xs l = conde [
    (xs === [] /\ l === zero);
    (fresh (h t m) (
      xs === h % t /\ l === succ m /\ length$^o$ t m))]
  let max$^o$ xs m = max$_1^o$ xs zero m
  let rec max$_1^o$ xs n m = conde [
    (xs === [] /\ m === n);
    (fresh (h t) (
      (xs === h % t) /\
      (conde [
        (le$^o$ h n ^true /\ max$_1^o$ t n m);
        (gt$^o$ h n ^true /\ max$_1^o$ t h m)])))]
  let rec le$^o$ x y b = conde [
    (x === zero /\ b === ^true);
    (fresh (x$_1$) (x === succ x$_1$ /\ y === zero /\ b === ^false));
    (fresh (x$_1$ y$_1$) (x === succ x$_1$ /\ y === succ y$_1$ /\ le$^o$ x$_1$ y$_1$ b))]
  let rec gt$^o$ x y b = conde [
    (x === zero /\ b === ^false);
    (fresh (x$_1$) (x === succ x$_1$ /\ y === zero /\ b === ^false));
    (fresh (x$_1$ y$_1$) (x === succ x$_1$ /\ y === succ y$_1$ /\ gt$^o$ x$_1$ y$_1$ b))]
  \end{lstlisting}
\end{minipage}
\end{figure*}

The ideal implementation is shown in fig.~\ref{ideal:maxandlength}.
It uses a recursive relation to compute the length and maximum element simultaneously while traversing the list once.

\begin{figure*}[!h]
  \centering
  \begin{minipage}{0.7\textwidth}
\begin{lstlisting}[label={ideal:maxandlength}, caption={Ideal implementation of maxlengtho}, captionpos=b, frame=tb]
  let maxLength$^o$ xs m l = maxLength$_1^o$ xs m zero l
  let rec maxLength$_1^o$ xs m n l = conde [
    (xs === [] /\ m === n /\ l === zero);
    (fresh (h t l$_1$)
       (xs === h % t) /\
       (l === succ l$_1$) /\
       (conde [
         (le$^o$ h n ^true /\ maxLength$_1^o$ t m n l);
         (gt$^o$ h n ^true /\ maxLength$_1^o$ t m h l)]))]
  \end{lstlisting}
\end{minipage}
\end{figure*}

We measured the execution time of \lstinline{maxLength$^o$ lst m l}, where \lstinline{lst} is a list of Peano numbers from $1$ to $100$.
Note, that the second disjunct in the implementation of both \lstinline{le$^o$} and \lstinline{gt$^o$} can never contribute into the result of \lstinline{maxLength$^o$} execution.
Thus among others we compared two ideal implentations: one includes these disjuncts, while the other removes them (see table~\ref{tbl:maxlen})


\begin{table}
  \centering
  \begin{tabular}{c||c}
                   & [1..100] \\ \hline\hline
  Original         & 2.286ms  \\ \hline
  Ideal           & 4.623ms  \\ \hline
  Ideal removed   & 3.133ms  \\ \hline
  \ecce             & 1.701ms  \\ \hline
  ConsCPD          & 2.578ms
  \end{tabular}

  \caption{Execution time of maxlengtho}
  \label{tbl:maxlen}
\end{table}

Surprising enough, the execution time of the ideal program is worse than of the original.
\ecce succeeds at improving the program performance, while conservative partial deduction worsens it a little.
\todo{why}

\subsection{Evaluator of Logic Formulas}

The relation \lstinline{eval$^o$} describes an evaluation of a subset of first-order logic formulas in a given substitution.
It has 3 arguments.
The first argument is a list of boolean values which serves as a substitution.
The $i$-th value of the substitution is the value of the $i$-th variable.
The second argument is a formula with the following abstract syntax.
A formula is either a \emph{variable} represented with a Peano number, a \emph{negation} of a formula, a \emph{conjunction} of two formulas or a \emph{disjunction} of two formulas.
The third argument is the value of the formula in the given substitution.

We specialize the \lstinline{eval$^o$} relation to synthesize formulas which evaluate to \lstinline{^true}\footnote{An arrow lifts ordinary values to the logic domain}.
To do so, we run the specializer for the goal with the last argument fixed to \lstinline{^true}, while the first two arguments remain free variables.
Depending on the way the \lstinline{eval$^o$} is implemented, different specializers generate significantly different residual programs.

\subsubsection{The Order of Relation Calls}

One possible implementation of the evaluator in the syntax of \oc is presented in listing~\ref{eval:last}.
Here the relation \lstinline{elem$^o$ subst v res} unifies \lstinline{res} with the value of the variable \lstinline{v} in the list \lstinline{subst}.
The relations \lstinline{and$^o$}, \lstinline{or$^o$}, and \lstinline{not$^o$} encode corresponding boolean operations.

\begin{figure*}[!h]
  \centering
  \begin{minipage}{0.95\textwidth}
    \begin{lstlisting}[label={eval:last}, caption={Evaluator of formulas with boolean operation last}, captionpos=b, frame=tb]
  let rec eval$^o$ subst fm res = conde [
    fresh (x y z v w) (
      (fm === var v /\ elem$^o$ subst v res);
      (fm === conj x y /\ eval$^o$ st x v /\ eval$^o$ st y w /\ and$^o$ v w res);
      (fm === disj x y /\ eval$^o$ st x v /\ eval$^o$ st y w /\ or$^o$ v w res);
      (fm === neg x /\ eval$^o$ st x v /\ not$^o$ v res))]
    \end{lstlisting}
  \end{minipage}
\end{figure*}

Note, that the calls to boolean relations \lstinline{and$^o$}, \lstinline{or$^o$}, and \lstinline{not$^o$} are placed last within each conjunction.
This poses a challenge to the CPD-based specializers.
Conjunctive partial deduction unfolds relation calls from left to right, so when specializing this relation for running backwards (i.e. considering the goal \lstinline{eval$^o$ subst fm ^true}), it fails to propagate the direction data onto recursive calls of \lstinline{eval$^o$}.
Knowing that \lstinline{res} is \lstinline{^true}, we can conclude that in the call \lstinline{and$^o$ v w res} variables \lstinline{v} and \lstinline{w} have to be \lstinline{^true} as well.
There are three possible options for these variables in the call \lstinline{or$^o$ v w res} and one for the call \lstinline{not$^o$}.
These variables are used in recursive calls of \lstinline{eval$^o$} and thus restrict the result of driving them.
CPD fails to recognize this, and thus unfolds recursive calls of \lstinline{eval$^o$} applied to fresh variables.
It leads to over-unfolding, big residual programs and poor performance.

The conservative partial deduction first unfolds those calls which are selected with the heuristic.
Since exploring boolean operations makes more sense, they are unfolded before recursive calls of \lstinline{eval$^o$}.
The way conservative partial deduction treats this program is the same as it treats the other implementation in which boolean operations are moved to the left, as shown in listing~\ref{eval:fst}.
This program is easier for CPD to transform which demonstrates how unequal is the behaviour of CPD for similar programs.

\begin{figure*}[!h]
  \centering
  \begin{minipage}{0.95\textwidth}
    \begin{lstlisting}[label={eval:fst}, caption={Evaluator of formulas with boolean operation second}, captionpos=b, frame=tb]
  let rec eval$^o$ subst fm res = conde [
    fresh (x y z v w) (
      (fm === var v /\ elem$^o$ subst v res);
      (fm === conj x y /\ and$^o$ v w res /\ eval$^o$ st x v /\ eval$^o$ st y w);
      (fm === disj x y /\ or$^o$ v w res /\ eval$^o$ st x v /\ eval$^o$ st y w);
      (fm === neg x /\ not$^o$ v res /\ eval$^o$ st x v))]
    \end{lstlisting}
  \end{minipage}
\end{figure*}

\subsubsection{Unfolding of Complex Relations}

Depending on the way a relation is implemented, it may take a different number of driving steps to reach the point when any useful information is derived through its unfolding.
Partial deduction tries to unfold every relation call unless it is unsafe, but not all relation calls serve to restrict the search space and thus should be unfolded.
In the implementation of \lstinline{eval$^o$} boolean operations can effectively restrict variables within the conjunctions and should be unfolded until they do.
But depending on the way they are implemented, the different number of driving steps should be performed for that.
The simplest way to implement these relations is with a table as demonstrated with the implementation of \lstinline{not$^o$} in listing~\ref{not:table}.
It is enough to unfold such relation calls once to derive useful information about variables.

\begin{figure*}[!h]
  \centering
  \begin{minipage}{0.45\textwidth}
    \begin{lstlisting}[label={not:table}, caption={Implementation of boolean \lstinline{not} as a table}, captionpos=b, frame=tb]
  let not$^o$ x y = conde [
     (x === ^true /\ y === ^false;
      x === ^false /\ y === ^true)]
    \end{lstlisting}
  \end{minipage}
\end{figure*}

The other way to implement boolean operations is via one basic boolean relation such as \lstinline{nand$^o$} which is, in turn, has a table-based implementation (see listing~\ref{not:nando}).
It will take several sequential unfoldings to derive that variables \lstinline{v} and \lstinline{w} should be \lstinline{^true} when considering a call \lstinline{and$^o$ v w ^true} implemented via a basic relation.
Conservative partial deduction drives the selected call until it derives useful substitutions for the variables involved while CPD with deterministic unfolding may fail to do so.

\begin{figure*}[!h]
  \centering
  \begin{minipage}{0.85\textwidth}
    \begin{lstlisting}[label={not:nando}, caption={Implementation of boolean operation via \lstinline{nand}}, captionpos=b, frame=tb]
  let not$^o$ x y = nand$^o$ x x y

  let or$^o$ x y z = nand$^o$ x x xx /\ nand$^o$ y y yy /\ nand$^o$ xx yy z

  let and$^o$ x y z = nand$^o$ x y xy /\ nand$^o$ xy xy z

  let nand$^o$ a b c = conde [
    ( a === ^false /\ b === ^false /\ c === ^true );
    ( a === ^false /\ b === ^true /\ c === ^true );
    ( a === ^true /\ b === ^false /\ c === ^true );
    ( a === ^true /\ b === ^true /\ c === ^false )]
    \end{lstlisting}
  \end{minipage}
\end{figure*}

\subsubsection{Evaluation Results}
In our study, we considered two implementations of \lstinline{eval$^o$}, one we call \lstinline{plain} and the other --- \lstinline{last}, and compared how specializers behave on them.
The \lstinline{plain} relation uses table-based boolean operations and places them further to the left in each conjunction.
The relation \lstinline{last} employs boolean operations implemented via \lstinline{nand$^o$} and place them at the end of each conjunction.
These two programs are complete opposites from the standpoint of CPD.
We measured the time necessary to generate $1000$ formulas over two variables which evaluate to \lstinline{^true} (averaged over 10 runs).


\begin{table}
  \centering
  \begin{tabular}{c||c||c}
                   & last    & plain  \\
  \hline\hline
  Original         & 0.695s  & 1.426s \\
  \hline
  \ecce             & 0.205s  & 0.264s \\
  \hline
  ConsCPD          & 0.132s  & 0.137s \\
  \end{tabular}

  \caption{Evaluation results}
  \label{tbl:eval}
\end{table}


\subsection{Unification and Path Search}

Besides evaluator of logic formulas we also run the transformers on the relation \lstinline{unify} which searches for a unifier of two terms and a relation \lstinline{isPath} specialized to search for paths in the graph.
These two relations are described in paper~\cite{lozov2019relational} so we will not go into too many details here.

The \lstinline{unify} relation was executed to find a unifier of two terms $f(X, X, g(Z, t))$ and $f(g(p, L), Y, Y)$.
The original \mk program fails to terminate on this goal in 30 seconds.
On this example, the most performant is the program generated by CPD (0.352 seconds) while the program generated by adding branching heuristic also fails to terminate in 30 seconds.
The conservative partial deduction shows some improvement with the residual program terminated within 1.947 seconds.
While driving this program, the conservative partial deduction does too much unfolding which negatively impacts the running time as compared to CPD.

The last test executed \lstinline{isPath} relation to search for 3 paths of length 7 in the graph with 20 vertices and 30 edges.
On this program, conservative partial deduction showed better transformation results than CPD, although the difference is not that drastic.

All evaluation results are presented in the table~\ref{tbl:unify}.
Each column corresponds to the relation being run as described above.
The row marked ``Original'' contains the running time of the original \mk relation before specialization, ``CPD'' and ``ConsCPD'' correspond to conjunctive and conservative partial deduction respectively while ``Branching'' is for the CPD modified with the branching heuristic.

\begin{table}
  \centering
  \begin{tabular}{c||c|c|c}
    \multirow{ 2}{*}{Terms} &
    f(X, a) & f(a \% b \% nil, c \% d \% nil, L) & f(X, X, g(Z, t))  \\
    \cline{2-4} &
    f(a, X) & f(X \% XS, YS, X \% ZS) & f(g(p, L), Y, Y)  \\
    \hline\hline
  Original         & $0.247*10^{-4}s$ & $>30s$  & $>30s$   \\
  \hline
  ConsCPD          & $0.084*10^{-4}s$ & $0.021s$ & $2.198s$  \\
  \hline
  \ecce             & $0.128*10^{-4}s$ & $0.026s$ & $1.340s$ \\
  \hline
  \end{tabular}

  \caption{Evaluation results of unification and path search}
  \label{tbl:unify}
\end{table}

% \begin{table}
%   \centering
%   \begin{tabular}{c||c|c|c||c}
%                    & \multicolumn{3}{c||}{unify} & isPath \\
%   \hline
%                    & first  & second & third     &        \\
%   \hline\hline
%   Original         & $0.247*10^{-4}s$ & $>30s$  & $>30s$  & $23.743s$ \\
%   \hline
%   ConsCPD          & $0.084*10^{-4}s$ & $0.021s$ & $2.198s$  & $1.786s$  \\
%   \hline
%   \ecce             & $0.128*10^{-4}s$ & $0.026s$ & $1.340s$  & $1.292s$ \\
%   \hline
%   \end{tabular}

%   \caption{Evaluation results of unification and path search}
%   \label{tbl:unify}
% \end{table}

\subsection{Typechecker-Term Generator}

This relation implements a typechecker for a tiny language.
Being executed in the backward direction it serves as a generator of terms of the given type.
The abstract syntax of the language is presented below.
The variables are represented with de Bruijn indices, thus let-binding does not specify which variable is being bound.


% \begin{align*}
%   &type \ term = \\
%   &| \ BConst \ of \ Bool \\
%   &| \ IConst \ of \ Int \\
%   &| \ Var \ of \ Int \\
%   &| \ Plus \ of \ term * term \\
%   &| \ Mult \ of \ term * term \\
%   &| \ Eq \ of \ term * term \\
%   &| \ Lt \ of \ term * term \\
%   &| \ Let \ of \ term * term \\
%   &| \ If \ of \ term * term * term
% \end{align*}

\[\begin{array}{lllll}
  type \ term = &\ BConst \ of \ Bool &| \ IConst \ of \ Int &| \ Var \ of \ Int & \\
  & | \ term + term &| \ term * term &| \ term = term &| \ term < term \\
  &| \ \underline{let} \ term \ \underline{in} \ term
  &\multicolumn{2}{l}{| \ \underline{if} \ term \ \underline{then} \ term \ \underline{else} \ term} &
\end{array}\]

The typing rules are straightforward and are presented below.
Boolean and integer constants have the corresponding types regardless of the environment.
Only terms of type integer can be summed up, multiplied or checked for being less or equal.
Any terms of the same type can be checked for equality.
If-then-else expression typechecks only if its condition is of type boolean, while both then- and else-branches have the same type.
An environment $\Gamma$ is an ordered list, in which the $i$-th element is the type of the variable with the $i$-th de Bruijn index.
To typecheck a let-binding, first, the term being bound is typechecked and is added in the beginning of the environment $\Gamma$, and then the body is typechecked in the context of the new environment.
Typechecking a variable with the index $i$ boils down to getting a $i$-th element of the list.

\begin{table}
  \setlength{\tabcolsep}{0.5cm}
  \centering
  \begin{tabular}{c c}
    \infer[]{\Gamma \vdash IConst \ i : Int}{} &
    \infer[]{\Gamma \vdash BConst \ b : Bool}{} \vspace{0.5cm} \\

    \infer[]{\Gamma \vdash t + s : Int}{\Gamma \vdash t : Int, \Gamma \vdash  s : Int} &
    \infer[]{\Gamma \vdash t * s : Int}{\Gamma \vdash t : Int, \Gamma \vdash  s : Int} \vspace{0.5cm} \\

    \infer[]{\Gamma \vdash t = s : Bool}{\Gamma \vdash t : \tau, \Gamma \vdash  s : \tau} &
    \infer[]{\Gamma \vdash t < s : Bool}{\Gamma \vdash t : Int, \Gamma \vdash  s : Int} \vspace{0.5cm} \\

    \infer[]{\Gamma \vdash \underline{let} \ v \ b : \tau}{\Gamma \vdash v : \tau_v, \ (\tau_v :: \Gamma) \vdash b : \tau} &
    \infer[\Gamma \lbrack v \rbrack = \tau]{\Gamma \vdash Var \ v : \tau}{} \vspace{0.5cm} \\

    \multicolumn{2}{c}{
      \infer[]{\Gamma \vdash \underline{if} \ c \ \underline{then} \ t \ \underline{else} \ s : \tau}{\Gamma \vdash c : Bool, \Gamma \vdash t : \tau, \Gamma \vdash s : \tau}
    }


  \end{tabular}
\end{table}

We compared two possible implementations of these typing rules.
The first one is obtained by unnesting of the functional program as described in~\cite{lozov2019relational}.
The second program is hand-written in \oc.
Each implementation has been transformed with conservative partial deducer and by \ecce.

We measured the time needed to generate 100 terms of type integer (averaged over 10 iterations).
\ecce significantly worsens the execution time for both implementations.
Conservative partial deduction improves the first implementation a little bit, while worsening the performance of the second implementation 3 times.

\begin{table}
  \centering
  \begin{tabular}{c||c||c}
              & Implementation 1 & Implementation 2 \\ \hline\hline
  Original    & 0.464s           & 0.057s           \\ \hline
  ConsCPD     & 0.448s           & 0.154s           \\ \hline
  \ecce        & 1.518s           & 2.543s           \\
  \end{tabular}

  \caption{Running time of generating 100 closed terms of type Int}
  \label{tbl:eval}
\end{table}

\todo{why}
