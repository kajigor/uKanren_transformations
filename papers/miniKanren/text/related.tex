\section{Related Work}

Specialization is an attractive technique aimed to improve the performance of a program if some of its arguments are known statically.
It is studied for functional, imperative and logic programing and comes in different forms: partial evaluation~\cite{jonesbook} and partial deduction~\cite{lloyd1991partial}, supercompilation~\cite{soerensen1996positive}, distillation~\cite{hamilton2007distillation} and many more.

\db{
  The heart of supercompilation-based techniques is \emph{driving}~---~a symbolic execution of a program through all possible execution paths.
  The result of driving is so-called \emph{process tree} where nodes correspond to \emph{configurations} presenting computation state, for example, a term in case of pure functional programming languages and each path in the tree~--~to some concrete program execution.
  The two main sources for supercompilation optimizations are aggressive information propagation about variable values, equalities, and disabilities and precomputing of all deterministic semantic evaluation steps, i.e. combining of consecutive process tree nodes with no branching, aka. \emph{deforestation}~\cite{TODO}.
  When the tree is constructed, the resulting program can be extracted from the process tree, this process is called \emph{residualization} and resulting program is called \emph{residual}.
  Of cause, process tree is possibly infinite.
  In order to ensure termination in supercompilation \emph{whistles}, heuristics to identify possibly infinite branches, are used.
  If the whistle signalled during some branch construction, the process is forced to be stoped.
  Then iether required source code will be copied to the residual program or process tree will be forced to fold in a \emph{process graph}.
  The main instrument ro perform such a folding is generalization.
  When two dangerously similar nodes are met, for example, two consecutive recursive calls of a function with accumulating parameter, and the first is not an instance of the second, then one may construct a new, generalized, node such that both of original nodes are instances of the last one, then one of the initial nodes is replaced with the generalized one.
  There are several ways to ensure process correctness and termination, the most familiar and popular one is \emph{homeomorphic embedding}~\cite{TODO}.
}

While supercompilation generally improves the behavior of input programs and distillation can even provide superlinear speedup, there are no ways to predict the effect of specialization on a given program in general case.
What is worse they rarely consider the residual program efficiency from the point of view of the target language evaluator.
The main optimization source is computing in advance all possible intermediate and statically-known semantics steps at transformation-time.
Other criteria like the size of the generated program or possible optimizations and execution cost of different language constructions by the target language evaluator are usually out of consideration~\cite{jonesbook}.
It is known that supercompilation may adversely affect GHC optimizations yielding standalone compilation more powerful~\cite{SCBE,TCES} and cause code explosion~\cite{SCHC}.
Moreover, it may be hard to predict the real speedup of any given program on concrete examples even disregarding problems above because of the complexity of the transformation algorithm.
The worst case for partial evaluation is when all static variables are used in a dynamic context, and there is a lot of advice on how to implement a partial evaluator as well as a target program so that specialization really improved its performance~\cite{jonesbook,bulyonkov84}.
There is lack of research in determining the classes of programs which transformers would definitely speed up.

Conjunctive partial deduction~\cite{de1999conjunctive} makes an effort to provide reasonable control for left-to-right evaluation strategy of \pro{}.
CPD constructs a tree which models goal evaluation and resembles SLD-NF tree.
After the tree is constructed, a residual program is generated from it.
The specialization is done in two levels of control: the local control determines the shape of the residual programs, while the global control ensures that every relation which can be called in the residual program is indeed defined.
The leaves of local control trees become nodes of the global control tree.
CPD analyses these nodes at the global level and runs local control for all those which are new.

At the local level CPD examines a conjunction of atoms by considering each atom one-by-one from left to right.
An atom is \emph{unfolded} if it is deemed safe.
When an atom is unfolded, a clause which head can be unified with the atom is found, and a new node is added into the tree where the atom in the conjunction is replaced with the body of that clause.
If there are more than one suitable head, then several branches are added into the tree which correspond to the disjunction in the residualized program.
An adaptation of CPD for the \mk{} programming language is described in~\cite{lozov2019relational}.

The most well-behaved strategy of local control in CPD for \pro{} is \emph{deterministic unfolding}.
An atom is unfolded only if only one suitable clause head exist for it with the one exception: it is allowed to unfold an atom non-deterministically once for one local control tree.
This means that if a non-deterministic atom is the left-most within a conjunction, it is most likely to be unfoldled and introduce a lot of
We believe this is the core problem with CPD which limits its power when applied to \mk{}.
The strategy of unfolding atoms from left to right is reasonable in the context of \pro{} because it mimics the way it executes.
But it often leads to larger global control trees and, as a result, bigger less efficient programs.
The evaluation result of a \mk{} program does not depend on the order of atoms (relation calls) within a conjunction, thus we believe a better result can be achieved by selecting a relation call which can restrict the number of branches in the tree.
We describe our approach which implements this idea in the next section.
